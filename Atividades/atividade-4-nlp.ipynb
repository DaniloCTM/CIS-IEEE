{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Atividade 4 - NLP\n\nO objetivo da segunda atividade é implementa conceitos do processamento de linguagem natural, para isso foi utlizado um dataset da amazon, no qual possui a review do usuário sobre um produto e a avalição de usuário. ","metadata":{}},{"cell_type":"markdown","source":"## Preparando o Ambiente","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O target desse problema era uma nota entre 0 e 5. Para simplificar o problema o target foi reduzido para 0 e 1, com 0 sendo a avalição negativa (rating<4) e 1 sendo a avaliação positiva (rating>=4).","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-music-reviews/Musical_instruments_reviews.csv')\ndf.dropna(axis=0)\ntrain, test = train_test_split(df, test_size = 0.1, random_state=42)\ntrain_x = train['reviewText']\ntrain_y = train['overall']\ntest_x = test['reviewText']\ntest_y = test['overall']\n\ndef good_or_bad(rating):\n    if rating in [4,5]:\n        return 1\n    else:\n        return 0\n    \ntrain_y = train_y.apply(good_or_bad)\ntest_y = test_y.apply(good_or_bad)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:34:49.199467Z","iopub.execute_input":"2023-08-24T21:34:49.200463Z","iopub.status.idle":"2023-08-24T21:34:49.396137Z","shell.execute_reply.started":"2023-08-24T21:34:49.200418Z","shell.execute_reply":"2023-08-24T21:34:49.395112Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Pré-processamento\n\nEm seguida realizamos o pré-processamento dos dados, nessa etapa removemos as stopwords e aplicamos lowercasing em todos os textos.","metadata":{}},{"cell_type":"code","source":"import nltk\nimport re\nnltk.download('stopwords')\n\ndef pre_processamento(data):\n    df = pd.DataFrame(columns=['text'])\n    for texto in data:\n        try:\n            letras_min =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto.lower())\n\n            stopwords = nltk.corpus.stopwords.words('english')\n            stop = set(stopwords)\n            sem_stopwords = [w for w in letras_min if w not in stop]\n\n            texto_limpo = f'{\" \".join(sem_stopwords)}'\n\n            nova_linha = pd.Series([texto_limpo], index=['text'])\n            df = pd.concat([df, nova_linha.to_frame().T], ignore_index=True)\n        except:\n            nova_linha = pd.Series(['nan'], index=['text'])\n            df = pd.concat([df, nova_linha.to_frame().T], ignore_index=True)\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:34:49.397485Z","iopub.execute_input":"2023-08-24T21:34:49.397835Z","iopub.status.idle":"2023-08-24T21:34:50.112813Z","shell.execute_reply.started":"2023-08-24T21:34:49.397801Z","shell.execute_reply":"2023-08-24T21:34:50.111823Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"train_x = pre_processamento(train_x)\n\ntest_x = pre_processamento(test_x)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:34:50.115477Z","iopub.execute_input":"2023-08-24T21:34:50.116863Z","iopub.status.idle":"2023-08-24T21:35:01.627780Z","shell.execute_reply.started":"2023-08-24T21:34:50.116824Z","shell.execute_reply":"2023-08-24T21:35:01.626819Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(train_x.head())\nprint(test_x.head())","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:35:01.629073Z","iopub.execute_input":"2023-08-24T21:35:01.631565Z","iopub.status.idle":"2023-08-24T21:35:01.641338Z","shell.execute_reply.started":"2023-08-24T21:35:01.631527Z","shell.execute_reply":"2023-08-24T21:35:01.639524Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                                                text\n0  work well nice low profile easy push button tr...\n1  loss initial tone pedal priority list love sou...\n2  friend mine guitar repair genus budding luthie...\n3  works great without polish good size ziplock b...\n4  given violin fiddle friend decided would never...\n                                                text\n0  using acoustic guitars straps decade sturdy co...\n1  sounds like great concept seem well made care ...\n2  recently ordered wide variety picks find ones ...\n3  two stands electric guitar bass version acoust...\n4  guitar sounds awesome stays tune well fan taka...\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = 15000\nembedding_dim = 16\nmax_length = 1081","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:35:01.644172Z","iopub.execute_input":"2023-08-24T21:35:01.644973Z","iopub.status.idle":"2023-08-24T21:35:01.652206Z","shell.execute_reply.started":"2023-08-24T21:35:01.644943Z","shell.execute_reply":"2023-08-24T21:35:01.651117Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Aplicando a Tokenização\n\nNessa etapa convertemos os textos para números por meio da tokenização, assim é possível aplicar o dado no modelo.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(num_words=vocab_size,oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(train_x['text'])\n\nword_index = tokenizer.word_index\n\ntraining_sequences = tokenizer.texts_to_sequences(train_x['text'])\ntraining_padded = pad_sequences(training_sequences, padding='post', maxlen=max_length,truncating='post')\n\ntest_sequences = tokenizer.texts_to_sequences(test_x['text'])\ntest_padded = pad_sequences(test_sequences, padding='post',maxlen=max_length,truncating='post')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:35:40.565087Z","iopub.execute_input":"2023-08-24T21:35:40.565464Z","iopub.status.idle":"2023-08-24T21:35:41.401569Z","shell.execute_reply.started":"2023-08-24T21:35:40.565432Z","shell.execute_reply":"2023-08-24T21:35:41.400627Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import Recall, Precision","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:35:01.653451Z","iopub.execute_input":"2023-08-24T21:35:01.653891Z","iopub.status.idle":"2023-08-24T21:35:01.663081Z","shell.execute_reply.started":"2023-08-24T21:35:01.653865Z","shell.execute_reply":"2023-08-24T21:35:01.661093Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Criando o Modelo\n\nAgora realizamos a criação de um modelo simples.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=[Recall(), 'accuracy', Precision()])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:26:10.347974Z","iopub.execute_input":"2023-08-24T21:26:10.348314Z","iopub.status.idle":"2023-08-24T21:26:10.614033Z","shell.execute_reply.started":"2023-08-24T21:26:10.348285Z","shell.execute_reply":"2023-08-24T21:26:10.612428Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 1081, 16)          240000    \n                                                                 \n global_average_pooling1d (G  (None, 16)               0         \n lobalAveragePooling1D)                                          \n                                                                 \n dense (Dense)               (None, 24)                408       \n                                                                 \n dense_1 (Dense)             (None, 1)                 25        \n                                                                 \n=================================================================\nTotal params: 240,433\nTrainable params: 240,433\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(training_padded, train_y, epochs=10, validation_data=(test_padded, test_y), verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:26:10.618133Z","iopub.execute_input":"2023-08-24T21:26:10.619332Z","iopub.status.idle":"2023-08-24T21:26:34.465460Z","shell.execute_reply.started":"2023-08-24T21:26:10.619282Z","shell.execute_reply":"2023-08-24T21:26:34.464168Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/10\n289/289 - 4s - loss: 0.4497 - recall: 0.9909 - accuracy: 0.8731 - precision: 0.8799 - val_loss: 0.3653 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 4s/epoch - 14ms/step\nEpoch 2/10\n289/289 - 2s - loss: 0.3674 - recall: 1.0000 - accuracy: 0.8791 - precision: 0.8791 - val_loss: 0.3654 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 8ms/step\nEpoch 3/10\n289/289 - 2s - loss: 0.3668 - recall: 1.0000 - accuracy: 0.8791 - precision: 0.8791 - val_loss: 0.3643 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 7ms/step\nEpoch 4/10\n289/289 - 2s - loss: 0.3659 - recall: 1.0000 - accuracy: 0.8791 - precision: 0.8791 - val_loss: 0.3640 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 8ms/step\nEpoch 5/10\n289/289 - 2s - loss: 0.3651 - recall: 1.0000 - accuracy: 0.8791 - precision: 0.8791 - val_loss: 0.3628 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 7ms/step\nEpoch 6/10\n289/289 - 2s - loss: 0.3643 - recall: 1.0000 - accuracy: 0.8791 - precision: 0.8791 - val_loss: 0.3621 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 8ms/step\nEpoch 7/10\n289/289 - 2s - loss: 0.3629 - recall: 1.0000 - accuracy: 0.8791 - precision: 0.8791 - val_loss: 0.3612 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 7ms/step\nEpoch 8/10\n289/289 - 2s - loss: 0.3615 - recall: 1.0000 - accuracy: 0.8791 - precision: 0.8791 - val_loss: 0.3604 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 7ms/step\nEpoch 9/10\n289/289 - 2s - loss: 0.3580 - recall: 1.0000 - accuracy: 0.8793 - precision: 0.8792 - val_loss: 0.3596 - val_recall: 1.0000 - val_accuracy: 0.8802 - val_precision: 0.8802 - 2s/epoch - 8ms/step\nEpoch 10/10\n289/289 - 2s - loss: 0.3532 - recall: 1.0000 - accuracy: 0.8795 - precision: 0.8794 - val_loss: 0.3521 - val_recall: 1.0000 - val_accuracy: 0.8812 - val_precision: 0.8811 - 2s/epoch - 7ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Esse modelo acabou tendo 88% de acuracia no dado de teste.","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"## Aplicando o LSTM\n\nAgora utilizamos um modelo de LSTM bidirecional para tentar obter um melhor resultado.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,64),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=[Recall(), 'accuracy', Precision()])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:35:01.664719Z","iopub.execute_input":"2023-08-24T21:35:01.665098Z","iopub.status.idle":"2023-08-24T21:35:05.195504Z","shell.execute_reply.started":"2023-08-24T21:35:01.665061Z","shell.execute_reply":"2023-08-24T21:35:05.194757Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, None, 64)          960000    \n                                                                 \n bidirectional (Bidirectiona  (None, 128)              66048     \n l)                                                              \n                                                                 \n dense (Dense)               (None, 64)                8256      \n                                                                 \n dense_1 (Dense)             (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 1,034,369\nTrainable params: 1,034,369\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(training_padded, train_y, epochs=10, validation_data=(test_padded, test_y), verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:35:44.992988Z","iopub.execute_input":"2023-08-24T21:35:44.993420Z","iopub.status.idle":"2023-08-24T21:42:10.355686Z","shell.execute_reply.started":"2023-08-24T21:35:44.993387Z","shell.execute_reply":"2023-08-24T21:42:10.354615Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/10\n289/289 - 79s - loss: 0.3576 - recall: 0.9963 - accuracy: 0.8778 - precision: 0.8805 - val_loss: 0.3006 - val_recall: 0.9956 - val_accuracy: 0.8851 - val_precision: 0.8876 - 79s/epoch - 274ms/step\nEpoch 2/10\n289/289 - 49s - loss: 0.2218 - recall: 0.9766 - accuracy: 0.9185 - precision: 0.9337 - val_loss: 0.2998 - val_recall: 0.9768 - val_accuracy: 0.8929 - val_precision: 0.9084 - 49s/epoch - 168ms/step\nEpoch 3/10\n289/289 - 38s - loss: 0.1246 - recall: 0.9852 - accuracy: 0.9579 - precision: 0.9675 - val_loss: 0.3761 - val_recall: 0.9823 - val_accuracy: 0.8870 - val_precision: 0.8988 - 38s/epoch - 132ms/step\nEpoch 4/10\n289/289 - 35s - loss: 0.0701 - recall: 0.9915 - accuracy: 0.9784 - precision: 0.9841 - val_loss: 0.4162 - val_recall: 0.9381 - val_accuracy: 0.8647 - val_precision: 0.9108 - 35s/epoch - 120ms/step\nEpoch 5/10\n289/289 - 30s - loss: 0.0374 - recall: 0.9956 - accuracy: 0.9885 - precision: 0.9914 - val_loss: 0.5298 - val_recall: 0.9325 - val_accuracy: 0.8608 - val_precision: 0.9114 - 30s/epoch - 105ms/step\nEpoch 6/10\n289/289 - 29s - loss: 0.0198 - recall: 0.9972 - accuracy: 0.9943 - precision: 0.9963 - val_loss: 0.6330 - val_recall: 0.9546 - val_accuracy: 0.8685 - val_precision: 0.9018 - 29s/epoch - 101ms/step\nEpoch 7/10\n289/289 - 28s - loss: 0.0182 - recall: 0.9979 - accuracy: 0.9944 - precision: 0.9957 - val_loss: 0.6950 - val_recall: 0.9613 - val_accuracy: 0.8763 - val_precision: 0.9043 - 28s/epoch - 98ms/step\nEpoch 8/10\n289/289 - 27s - loss: 0.0127 - recall: 0.9978 - accuracy: 0.9962 - precision: 0.9979 - val_loss: 0.7573 - val_recall: 0.9237 - val_accuracy: 0.8539 - val_precision: 0.9116 - 27s/epoch - 95ms/step\nEpoch 9/10\n289/289 - 28s - loss: 0.0083 - recall: 0.9990 - accuracy: 0.9981 - precision: 0.9988 - val_loss: 0.7529 - val_recall: 0.9369 - val_accuracy: 0.8588 - val_precision: 0.9059 - 28s/epoch - 96ms/step\nEpoch 10/10\n289/289 - 27s - loss: 0.0066 - recall: 0.9986 - accuracy: 0.9975 - precision: 0.9985 - val_loss: 0.8216 - val_recall: 0.9447 - val_accuracy: 0.8637 - val_precision: 0.9047 - 27s/epoch - 92ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Com esse modelo consegimos ótimos resultados, a acurácia no treinamento chegou em 99% e no teste chegou em 90%","metadata":{}}]}